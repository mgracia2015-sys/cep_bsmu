import streamlit as st
import warnings
from docx import Document
from docx.shared import Pt, Cm
from docx.enum.text import WD_ALIGN_PARAGRAPH
import re
from datetime import datetime
import io

# –î–ª—è Google API
from googleapiclient.discovery import build
import google.auth

warnings.filterwarnings("ignore")

st.set_page_config(page_title="–†–µ–¥–∞–∫—Ç–æ—Ä –Ω–∞—É–∫–æ–≤–∏—Ö —Å—Ç–∞—Ç–µ–π", layout="centered")

st.title("üìù –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è —Å—Ç–∞—Ç—Ç—ñ")

# ============================================================
# 1Ô∏è‚É£ –Ü–ù–¢–ï–†–§–ï–ô–° STREAMLIT (–ó–∞–º—ñ—Å—Ç—å Radio Buttons Colab)
# ============================================================

col1, col2 = st.columns(2)

with col1:
    language_choice = st.radio(
        "–û–±–µ—Ä—ñ—Ç—å –º–æ–≤—É:",
        options=[('–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞', 'uk'), ('English', 'en')],
        format_func=lambda x: x[0]
    )
    language = language_choice[1]

with col2:
    article_type_choice = st.radio(
        "–¢–∏–ø —Å—Ç–∞—Ç—Ç—ñ:",
        options=[
            ('–û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è', 'original'),
            ('–ö–ª—ñ–Ω—ñ—á–Ω–∏–π –≤–∏–ø–∞–¥–æ–∫', 'case'),
            ('–û–≥–ª—è–¥ –ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏', 'review')
        ],
        format_func=lambda x: x[0]
    )
    article_type = article_type_choice[1]

uploaded_file = st.file_uploader("–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ñ–∞–π–ª .docx", type=["docx"])

# –ö–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫—É
if st.button("üöÄ –û–±—Ä–æ–±–∏—Ç–∏ —Å—Ç–∞—Ç—Ç—é") and uploaded_file is not None:
    
    # ============================================================
    # 2Ô∏è‚É£ –ì–û–õ–û–í–ù–ê –õ–û–ì–Ü–ö–ê (–ë–ï–ó –ó–ú–Ü–ù –í –ê–õ–ì–û–†–ò–¢–ú–Ü)
    # ============================================================
    
    report = []
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
    doc = Document(uploaded_file)
    file_name = uploaded_file.name
    report.append("–§–∞–π–ª –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: " + file_name)

    # 2.3 –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç–∞ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è –ø–æ–ª—ñ–≤ —Å—Ç–æ—Ä—ñ–Ω–∫–∏
    section = doc.sections[0]
    if section.top_margin != Cm(2):
        section.top_margin = Cm(2)
        report.append("–í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ –≤–µ—Ä—Ö–Ω—î –ø–æ–ª–µ –Ω–∞ 2 —Å–º")
    if section.bottom_margin != Cm(2):
        section.bottom_margin = Cm(2)
        report.append("–í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ –Ω–∏–∂–Ω—î –ø–æ–ª–µ –Ω–∞ 2 —Å–º")
    if section.right_margin != Cm(2):
        section.right_margin = Cm(2)
        report.append("–í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ –ø—Ä–∞–≤–µ –ø–æ–ª–µ –Ω–∞ 2 —Å–º")
    if section.left_margin != Cm(2):
        section.left_margin = Cm(2)
        report.append("–í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ –ª—ñ–≤–µ –ø–æ–ª–µ –Ω–∞ 2 —Å–º")

    # 2.4 –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç–∞ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è —Ñ–æ—Ä–º–∞—Ç—É —Ç–µ–∫—Å—Ç—É
    for paragraph in doc.paragraphs:
        paragraph_format = paragraph.paragraph_format
        paragraph_format.line_spacing = 1.5
        paragraph_format.space_before = Pt(0)
        paragraph_format.space_after = Pt(0)
        if paragraph.alignment == WD_ALIGN_PARAGRAPH.JUSTIFY:
            paragraph_format.first_line_indent = Cm(1.25)
        for run in paragraph.runs:
            run.font.name = "Times New Roman"
            run.font.size = Pt(14)
    report.append("–ü–µ—Ä–µ–≤—ñ—Ä–µ–Ω–æ —Ç–∞ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–æ —Ñ–æ—Ä–º–∞—Ç —Ç–µ–∫—Å—Ç—É")

    # 2.5 –£–î–ö, –Ω–∞–∑–≤–∞ —Ç–∞ –∞–≤—Ç–æ—Ä–∏
    paragraphs = doc.paragraphs

    # ---- –£–î–ö ----
    if len(paragraphs) >= 1:
        first = paragraphs[0]
        if not first.text.startswith("–£–î–ö"):
            first.text = "–£–î–ö 000.00"
            report.append("–î–æ–¥–∞–Ω–æ –£–î–ö")
        for run in first.runs:
            run.font.bold = True
        report.append("–£–î–ö –ø–µ—Ä–µ–≤—ñ—Ä–µ–Ω–æ/–≤–∏–ø—Ä–∞–≤–ª–µ–Ω–æ")

    # ---- –ù–∞–∑–≤–∞ —Å—Ç–∞—Ç—Ç—ñ ----
    if len(paragraphs) >= 2:
        title_para = paragraphs[1]
        title_text = title_para.text.replace("\n", " ").strip().upper()
        title_para.text = title_text
        for run in title_para.runs:
            run.font.bold = True
        report.append("–ù–∞–∑–≤–∞ —Å—Ç–∞—Ç—Ç—ñ –ø–µ—Ä–µ–≤—ñ—Ä–µ–Ω–∞ —Ç–∞ –ø—Ä–∏–≤–µ–¥–µ–Ω–∞ –¥–æ —Ñ–æ—Ä–º–∞—Ç—É (–≤–µ–ª–∏–∫–∏–º–∏ –ª—ñ—Ç–µ—Ä–∞–º–∏, –æ–¥–∏–Ω –∞–±–∑–∞—Ü, –∂–∏—Ä–Ω–∏–π)")

        # ---- –ê–≤—Ç–æ—Ä–∏ ----
        if len(paragraphs) >= 3:
            authors_para = paragraphs[2]
            authors_list = authors_para.text.split(',')
            new_authors = []
            for author in authors_list:
                author = author.strip()
                parts = author.split()
                if len(parts) >= 2:
                    if parts[0].endswith("."): 
                        initials = parts[0]
                        surname = parts[1]
                        rest = " ".join(parts[2:])
                    else:
                        surname = parts[0]
                        initials = parts[1]
                        rest = " ".join(parts[2:])
                    author_text = f"{initials} {surname}"
                    if rest: author_text += f" {rest}"
                    new_authors.append(author_text)
                else:
                    new_authors.append(author)
            
            authors_para.text = ", ".join(new_authors)
            for run in authors_para.runs:
                run.font.bold = True
                run.font.italic = True
            report.append("–ê–≤—Ç–æ—Ä–∏ –ø–µ—Ä–µ–≤—ñ—Ä–µ–Ω—ñ —Ç–∞ –≤—ñ–¥—Ñ–æ—Ä–º–∞—Ç–æ–≤–∞–Ω—ñ (–∂–∏—Ä–Ω–∏–π + –∫—É—Ä—Å–∏–≤, —ñ–Ω—ñ—Ü—ñ–∞–ª–∏ –ø–µ—Ä–µ–¥ –ø—Ä—ñ–∑–≤–∏—â–µ–º, —Ü–∏—Ñ—Ä–∏ –∞—Ñ—ñ–ª—ñ–∞—Ü—ñ–π –∑–±–µ—Ä–µ–∂–µ–Ω—ñ)")

    # –ê—Ñ—ñ–ª—ñ–∞—Ü—ñ—è —Ç–∞ –∞–Ω–æ—Ç–∞—Ü—ñ—è
    max_affiliation_number = 0
    if len(paragraphs) >= 3:
        authors_para = paragraphs[2]
        numbers = re.findall(r'\d+', authors_para.text)
        if numbers:
            max_affiliation_number = max([int(n) for n in numbers])

    affiliation_start = 3
    affiliation_end = affiliation_start + max_affiliation_number if max_affiliation_number > 0 else affiliation_start + 1
    
    affiliation_paragraphs = paragraphs[affiliation_start:affiliation_end]
    for para in affiliation_paragraphs:
        for run in para.runs:
            run.font.bold = False
            run.font.italic = False
    report.append(f"–ê—Ñ—ñ–ª—ñ–∞—Ü—ñ—è –∞–≤—Ç–æ—Ä—ñ–≤ –ø–µ—Ä–µ–≤—ñ—Ä–µ–Ω–∞ ({affiliation_end - affiliation_start} —Ä—è–¥–∫—ñ–≤)")

    # –ê–Ω–æ—Ç–∞—Ü—ñ—è
    abstract_start = affiliation_end
    abstract_end = abstract_start
    keywords_found = False
    for i in range(abstract_start, len(paragraphs)):
        para_text_lower = paragraphs[i].text.lower()
        if "–∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞" in para_text_lower or "keywords" in para_text_lower:
            abstract_end = i + 1
            keywords_found = True
            break
    if not keywords_found: abstract_end = len(paragraphs)

    abstract_paragraphs = paragraphs[abstract_start:abstract_end]
    abstract_text = ""
    for para in abstract_paragraphs:
        abstract_text += para.text + "\n"
        para.paragraph_format.first_line_indent = None
        for run in para.runs:
            current_bold = run.font.bold
            run.font.italic = True
            if current_bold is not None: run.font.bold = current_bold

    abstract_length = len(abstract_text)
    if abstract_length < 1800 or abstract_length > 2500:
        report.append(f"‚ö†Ô∏è –ü–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è: –¥–æ–≤–∂–∏–Ω–∞ –∞–Ω–æ—Ç–∞—Ü—ñ—ó {abstract_length} —Å–∏–º–≤–æ–ª—ñ–≤ (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ 1800‚Äì2500)")
    report.append("–ê–Ω–æ—Ç–∞—Ü—ñ—è –ø–µ—Ä–µ–≤—ñ—Ä–µ–Ω–∞ —Ç–∞ –≤—ñ–¥—Ñ–æ—Ä–º–∞—Ç–æ–≤–∞–Ω–∞ (–∫—É—Ä—Å–∏–≤)")

    # 2.X –î–†–£–ì–ê –ú–û–í–ù–ê –í–ï–†–°–Ü–Ø
    second_start = abstract_end
    while second_start < len(paragraphs) and not paragraphs[second_start].text.strip():
        second_start += 1

    if second_start < len(paragraphs):
        title2_para = paragraphs[second_start]
        title2_text = title2_para.text.replace("\n", " ").strip().upper()
        title2_para.text = title2_text
        for run in title2_para.runs: run.font.bold = True
        report.append("–ù–∞–∑–≤–∞ –¥—Ä—É–≥–æ—é –º–æ–≤–æ—é –ø–µ—Ä–µ–≤—ñ—Ä–µ–Ω–∞ —Ç–∞ –ø—Ä–∏–≤–µ–¥–µ–Ω–∞ –¥–æ —Ñ–æ—Ä–º–∞—Ç—É")

        authors2_index = second_start + 1
        while authors2_index < len(paragraphs) and not paragraphs[authors2_index].text.strip():
            authors2_index += 1

        if authors2_index < len(paragraphs):
            authors2_para = paragraphs[authors2_index]
            authors_list = authors2_para.text.split(',')
            new_authors = []
            for author in authors_list:
                author = author.strip()
                parts = author.split()
                if len(parts) >= 2:
                    if parts[0].endswith("."):
                        initials, surname = parts[0], parts[1]
                        rest = " ".join(parts[2:])
                    else:
                        surname, initials = parts[0], parts[1]
                        rest = " ".join(parts[2:])
                    author_text = f"{initials} {surname}"
                    if rest: author_text += f" {rest}"
                    new_authors.append(author_text)
                else: new_authors.append(author)
            authors2_para.text = ", ".join(new_authors)
            for run in authors2_para.runs:
                run.font.bold, run.font.italic = True, True
            report.append("–ê–≤—Ç–æ—Ä–∏ –¥—Ä—É–≥–æ—é –º–æ–≤–æ—é –≤—ñ–¥—Ñ–æ—Ä–º–∞—Ç–æ–≤–∞–Ω—ñ")

            affiliation2_start = authors2_index + 1
            affiliation2_end = affiliation2_start + (affiliation_end - affiliation_start)
            affiliation2_paragraphs = paragraphs[affiliation2_start:affiliation2_end]
            for para in affiliation2_paragraphs:
                for run in para.runs:
                    run.font.bold, run.font.italic = False, False
            report.append(f"–ê—Ñ—ñ–ª—ñ–∞—Ü—ñ—è –¥—Ä—É–≥–æ—é –º–æ–≤–æ—é –ø–µ—Ä–µ–≤—ñ—Ä–µ–Ω–∞ ({len(affiliation2_paragraphs)} —Ä—è–¥–∫—ñ–≤)")

            abstract2_start = affiliation2_end
            abstract2_end = abstract2_start
            keywords2_found = False
            for i in range(abstract2_start, len(paragraphs)):
                para_text_lower = paragraphs[i].text.lower()
                if "–∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞" in para_text_lower or "keywords" in para_text_lower:
                    abstract2_end = i + 1
                    keywords2_found = True
                    break
            if not keywords2_found: abstract2_end = len(paragraphs)
            
            abstract2_paragraphs = paragraphs[abstract2_start:abstract2_end]
            for para in abstract2_paragraphs:
                para.paragraph_format.first_line_indent = None
                for run in para.runs:
                    current_bold = run.font.bold
                    run.font.italic = True
                    if current_bold is not None: run.font.bold = current_bold
            report.append("–ê–Ω–æ—Ç–∞—Ü—ñ—è –¥—Ä—É–≥–æ—é –º–æ–≤–æ—é –ø–µ—Ä–µ–≤—ñ—Ä–µ–Ω–∞ —Ç–∞ –≤—ñ–¥—Ñ–æ—Ä–º–∞—Ç–æ–≤–∞–Ω–∞ (–∫—É—Ä—Å–∏–≤)")

    # 3. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤
    required_elements = {
        "uk": { 
            "original": {
                "abstract_uk": ["–ú–µ—Ç–∞ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è", "–ú–∞—Ç–µ—Ä—ñ–∞–ª–∏ —ñ –º–µ—Ç–æ–¥–∏", "–†–µ–∑—É–ª—å—Ç–∞—Ç–∏", "–í–∏—Å–Ω–æ–≤–∫–∏", "–ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞"],
                "abstract_en": ["Objective", "Materials and methods", "Results", "Conclusions", "Key words"],
                "main_text": ["–í—Å—Ç—É–ø", "–ú–µ—Ç–∞ —Ä–æ–±–æ—Ç–∏", "–ú–∞—Ç–µ—Ä—ñ–∞–ª —ñ –º–µ—Ç–æ–¥–∏ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è", "–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ —Ç–∞ —ó—Ö –æ–±–≥–æ–≤–æ—Ä–µ–Ω–Ω—è", "–í–∏—Å–Ω–æ–≤–∫–∏", "–ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–∏ –ø–æ–¥–∞–ª—å—à–∏—Ö –¥–æ—Å–ª—ñ–¥–∂–µ–Ω—å", "–°–ø–∏—Å–æ–∫ –ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏", "References"]
            },
            "case": {
                "abstract_uk": ["–í–∏—Å–Ω–æ–≤–∫–∏"], "abstract_en": ["Conclusions"],
                "main_text": ["–í—Å—Ç—É–ø", "–û–ø–∏—Å –∫–ª—ñ–Ω—ñ—á–Ω–æ–≥–æ –≤–∏–ø–∞–¥–∫—É", "–í–∏—Å–Ω–æ–≤–∫–∏", "–°–ø–∏—Å–æ–∫ –ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏", "References"]
            },
            "review": {
                "abstract_uk": ["–ú–µ—Ç–∞ —Ä–æ–±–æ—Ç–∏", "–û—Å–Ω–æ–≤–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞", "–í–∏—Å–Ω–æ–≤–∫–∏"],
                "abstract_en": ["Objective", "Main Text", "Conclusions"],
                "main_text": ["–í—Å—Ç—É–ø", "–ú–µ—Ç–∞ —Ä–æ–±–æ—Ç–∏", "–û—Å–Ω–æ–≤–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞", "–í–∏—Å–Ω–æ–≤–∫–∏", "–°–ø–∏—Å–æ–∫ –ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏", "References"]
            }
        },
        "en": {
            "original": {
                "abstract_en": ["Objective", "Materials and methods", "Results", "Conclusions", "Key words"],
                "abstract_uk": ["–ú–µ—Ç–∞ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è", "–ú–∞—Ç–µ—Ä—ñ–∞–ª–∏ —ñ –º–µ—Ç–æ–¥–∏", "–†–µ–∑—É–ª—å—Ç–∞—Ç–∏", "–í–∏—Å–Ω–æ–≤–∫–∏", "–ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞"],
                "main_text": ["Introduction", "Objective", "Materials and Methods", "Results and Discussion", "Conclusions", "Prospects for further research", "References"]
            },
            "case": {
                "abstract_en": ["Conclusions"], "abstract_uk": ["–í–∏—Å–Ω–æ–≤–∫–∏"],
                "main_text": ["Introduction", "Case description", "Conclusions", "References"]
            },
            "review": {
                "abstract_en": ["Objective", "Materials and methods", "Results", "Conclusions", "Key words"],
                "abstract_uk": ["–ú–µ—Ç–∞ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è", "–ú–∞—Ç–µ—Ä—ñ–∞–ª–∏ —ñ –º–µ—Ç–æ–¥–∏", "–†–µ–∑—É–ª—å—Ç–∞—Ç–∏", "–í–∏—Å–Ω–æ–≤–∫–∏", "–ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞"],
                "main_text": ["Introduction", "Objective", "Main part", "Conclusions", "References"]
            }
        }
    }

    selected_structure = required_elements[language][article_type]
    missing_elements = []
    for section_name, elements in selected_structure.items():
        for element in elements:
            found = False
            for paragraph in doc.paragraphs:
                if paragraph.text.strip().lower().startswith(element.lower()):
                    found = True
                    break
            if not found: missing_elements.append(f"{section_name}: {element}")

    if missing_elements:
        report.append("‚ùå –í—ñ–¥—Å—É—Ç–Ω—ñ –∞–±–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ñ –µ–ª–µ–º–µ–Ω—Ç–∏:")
        for item in missing_elements: report.append(f"   - {item}")
    else: report.append("‚úÖ –£—Å—ñ –æ–±–æ–≤‚Äô—è–∑–∫–æ–≤—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ñ –µ–ª–µ–º–µ–Ω—Ç–∏ –ø—Ä–∏—Å—É—Ç–Ω—ñ —Ç–∞ –æ—Ñ–æ—Ä–º–ª–µ–Ω—ñ –ø—Ä–∞–≤–∏–ª—å–Ω–æ")

    # –ü–ï–†–ï–í–Ü–†–ö–ê –õ–Ü–¢–ï–†–ê–¢–£–†–ò
    references_start, references_title = None, None
    titles_to_find = ["—Å–ø–∏—Å–æ–∫ –ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏", "references"]
    for i, para in enumerate(paragraphs):
        text_lower = para.text.strip().lower()
        if any(text_lower.startswith(t) for t in titles_to_find):
            references_start, references_title = i + 1, para.text.strip()
            break

    if references_start is None:
        report.append("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —Ä–æ–∑–¥—ñ–ª –ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏")
    else:
        reference_paragraphs = []
        for para in paragraphs[references_start:]:
            text = para.text.strip()
            if not text: continue
            if re.search(r"(author|email|e-mail|correspondence|–∞–¥—Ä–µ—Å–∞|–∫–æ–Ω—Ç–∞–∫—Ç)", text.lower()): break
            reference_paragraphs.append(text)
        
        reference_count = len(reference_paragraphs)
        if article_type in ["original", "case"]:
            if reference_count > 15: report.append(f"‚ö†Ô∏è –î–∂–µ—Ä–µ–ª: {reference_count} (–¥–æ–ø—É—Å—Ç–∏–º–æ –Ω–µ –±—ñ–ª—å—à–µ 15)")
            else: report.append(f"–ö—ñ–ª—å–∫—ñ—Å—Ç—å –¥–∂–µ—Ä–µ–ª: {reference_count}")
        elif article_type == "review":
            if reference_count < 50: report.append(f"‚ö†Ô∏è –î–∂–µ—Ä–µ–ª: {reference_count} (–¥–ª—è –æ–≥–ª—è–¥—É –ø–æ—Ç—Ä—ñ–±–Ω–æ –Ω–µ –º–µ–Ω—à–µ 50)")
            else: report.append(f"–ö—ñ–ª—å–∫—ñ—Å—Ç—å –¥–∂–µ—Ä–µ–ª: {reference_count}")

        expected_number, numbering_errors, vancouver_errors = 1, False, False
        for ref in reference_paragraphs:
            match = re.match(r"^(\d+)[\.\)]", ref)
            if match:
                if int(match.group(1)) != expected_number: numbering_errors = True
                expected_number += 1
            else: numbering_errors = True
            if not re.search(r"\b(19|20)\d{2}\b", ref): vancouver_errors = True
        
        if vancouver_errors: report.append("‚ö†Ô∏è –ú–æ–∂–ª–∏–≤–µ –ø–æ—Ä—É—à–µ–Ω–Ω—è Vancouver style")
        else: report.append("–°—Ç–∏–ª—å –ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏ –≤–∏–≥–ª—è–¥–∞—î –∫–æ—Ä–µ–∫—Ç–Ω–∏–º (–±–∞–∑–æ–≤–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞)")

    # 2.6 –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É –≤ –ø–∞–º'—è—Ç—å –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
    bio = io.BytesIO()
    doc.save(bio)
    
    # 2.7 –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑–≤—ñ—Ç—É –≤ Streamlit
    st.subheader("=== –ó–í–Ü–¢ –ü–†–û –í–ù–ï–°–ï–ù–Ü –ó–ú–Ü–ù–ò ===")
    
    sections = {"–§–∞–π–ª": [], "–ü–æ–ª—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏": [], "–§–æ—Ä–º–∞—Ç —Ç–µ–∫—Å—Ç—É": [], "–ù–∞–∑–≤–∞/–£–î–ö/–ê–≤—Ç–æ—Ä–∏": [], "–Ü–Ω—à–µ": []}
    for item in report:
        if "–§–∞–π–ª –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ" in item: sections["–§–∞–π–ª"].append(item)
        elif "–ø–æ–ª–µ" in item: sections["–ü–æ–ª—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏"].append(item)
        elif any(x in item for x in ["—à—Ä–∏—Ñ—Ç", "–º—ñ–∂—Ä—è–¥–∫–æ–≤–∏–π", "–≤—ñ–¥—Å—Ç—É–ø", "—Ñ–æ—Ä–º–∞—Ç —Ç–µ–∫—Å—Ç—É"]): sections["–§–æ—Ä–º–∞—Ç —Ç–µ–∫—Å—Ç—É"].append(item)
        elif any(x in item for x in ["–£–î–ö", "–ù–∞–∑–≤–∞", "–ê–≤—Ç–æ—Ä–∏"]): sections["–ù–∞–∑–≤–∞/–£–î–ö/–ê–≤—Ç–æ—Ä–∏"].append(item)
        else: sections["–Ü–Ω—à–µ"].append(item)

    for sec, items in sections.items():
        if items:
            with st.expander(f"üìå {sec}", expanded=True):
                for it in list(dict.fromkeys(items)):
                    st.write(f"- {it}")

    st.success("–ì–æ—Ç–æ–≤–æ ‚úÖ –§–∞–π–ª –≤—ñ–¥—Ñ–æ—Ä–º–∞—Ç–æ–≤–∞–Ω–æ.")
    
    # –ö–Ω–æ–ø–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
    st.download_button(
        label="üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–∏–π —Ñ–∞–π–ª",
        data=bio.getvalue(),
        file_name=f"fixed_{file_name}",
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    )

    # 2.8 Google Docs Log (–°–ø—Ä–æ–±–∞ –≤–∏–∫–æ–Ω–∞—Ç–∏, —è–∫—â–æ —î —Å–µ—Ä—Ç–∏—Ñ—ñ–∫–∞—Ç–∏)
    # –ü–†–ò–ú–Ü–¢–ö–ê: –£ Streamlit Cloud –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è —á–µ—Ä–µ–∑ auth.authenticate_user() –Ω–µ –ø—Ä–∞—Ü—é–≤–∞—Ç–∏–º–µ —è–∫ —É Colab.
    # –ü–æ—Ç—Ä—ñ–±–µ–Ω —Ñ–∞–π–ª service_account.json –∞–±–æ –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω—ñ Secrets.
    try:
        # –¶—è —á–∞—Å—Ç–∏–Ω–∞ –∑–∞–ª–∏—à–∏—Ç—å—Å—è —Ä–æ–±–æ—á–æ—é –¢–Ü–õ–¨–ö–ò —è–∫—â–æ –∑–∞–ø—É—â–µ–Ω–æ –ª–æ–∫–∞–ª—å–Ω–æ –∑ –Ω–∞—è–≤–Ω–∏–º –±—Ä–∞—É–∑–µ—Ä–æ–º
        # –∞–±–æ –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–∏–º–∏ –∑–º—ñ–Ω–Ω–∏–º–∏ –æ—Ç–æ—á–µ–Ω–Ω—è Google.
        # –í Streamlit Cloud –≤–æ–Ω–∞ —à–≤–∏–¥—à–µ –∑–∞ –≤—Å–µ –≤–∏–¥–∞—Å—Ç—å –ø–æ–º–∏–ª–∫—É –±–µ–∑ –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å.
        # auth.authenticate_user()  <-- –í–∏–¥–∞–ª–µ–Ω–æ, –±–æ —Ü–µ —Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω–æ –¥–ª—è Colab
        creds, _ = google.auth.default()
        service = build('docs', 'v1', credentials=creds)
        current_date = datetime.now().strftime("%d.%m.%Y")
        udk_title = paragraphs[1].text if len(paragraphs) > 0 else "–ù–µ–≤—ñ–¥–æ–º–æ"
        authors = paragraphs[2].text if len(paragraphs) > 2 else "–ù–µ–≤—ñ–¥–æ–º–æ"
        text_to_insert = f"\n[{current_date}] –ê–í–¢–û–†: {authors} | –°–¢–ê–¢–¢–Ø: {udk_title}\n"
        requests = [{'insertText': {'location': {'index': 1}, 'text': text_to_insert}}]
        SHARED_LOG_DOC_ID = '13j6RQGukjUHqTu4doCFeqVtS7PlbrfBIKXVG8Kg7qzo'
        service.documents().batchUpdate(documentId=SHARED_LOG_DOC_ID, body={'requests': requests}).execute()
        st.info("‚úÖ –î–∞–Ω—ñ —É—Å–ø—ñ—à–Ω–æ –¥–æ–¥–∞–Ω—ñ —É Google Docs")
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –ó–∞–ø–∏—Å –≤ –∂—É—Ä–Ω–∞–ª Google Docs –ø—Ä–æ–ø—É—â–µ–Ω–æ (–ø–æ—Ç—Ä—ñ–±–Ω–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –¥–æ—Å—Ç—É–ø—É): {e}")

elif uploaded_file is None:
    st.info("–ë—É–¥—å –ª–∞—Å–∫–∞, –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ñ–∞–π–ª, —â–æ–± –ø–æ—á–∞—Ç–∏.")