import streamlit as st
import re
from docx import Document
from docx.shared import Pt, Cm
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.ns import qn
from io import BytesIO

# --- –§–£–ù–ö–¶–Ü–á –§–û–†–ú–ê–¢–£–í–ê–ù–ù–Ø ---

def apply_base_style(paragraph, first_line=1.25, space_before=0):
    paragraph.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
    # –ü–æ—á–∞—Ç–∫–æ–≤—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è (–±—É–¥—É—Ç—å –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞–Ω—ñ —Ñ—ñ–Ω–∞–ª—å–Ω–∏–º —Ü–∏–∫–ª–æ–º, –∞–ª–µ –∑–∞–ª–∏—à–∞—î–º–æ –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏)
    paragraph.paragraph_format.first_line_indent = Cm(first_line)
    paragraph.paragraph_format.space_before = Pt(space_before)

def add_run(paragraph, text, bold=False, italic=False):
    run = paragraph.add_run(text)
    run.font.name = 'Times New Roman'
    run.font.size = Pt(14) # –û–¥—Ä–∞–∑—É —Å—Ç–∞–≤–∏–º–æ 14
    run.bold, run.italic = bold, italic
    run._element.rPr.rFonts.set(qn('w:eastAsia'), 'Times New Roman')
    return run

def fix_authors_metadata(text):
    parts = re.split(r'[,;]', text)
    fixed = []
    for p in parts:
        p = p.strip()
        res = re.sub(r'([–ê-–Ø–Å–Ü–á–Ñ“êA-Z][–∞-—è—ë—ñ—ó—î“ëa-z]+)\s+([–ê-–Ø–Å–Ü–á–Ñ“êA-Z]\.\s?[–ê-–Ø–Å–Ü–á–Ñ“êA-Z]\.)', r'\2 \1', p)
        fixed.append(res)
    return ", ".join(fixed)

def format_vancouver(text):
    text = text.replace('"', '').replace('¬´', '').replace('¬ª', '')
    text = re.sub(r'([A-Z–ê-–Ø][a-z–∞-—è]+)\s+([A-Z–ê-–Ø])\.\s?([A-Z–ê-–Ø])\.', r'\1 \2\3', text)
    text = re.sub(r'([A-Z–ê-–Ø][a-z–∞-—è]+)\s+([A-Z–ê-–Ø])\.', r'\1 \2', text)
    text = re.sub(r'(\d{4})[\.\s,‚Äì‚Äî]*Vol\.?\s*(\d+)[\.\s,‚Äì‚Äî]*[Nn]o\.?\s*(\d+)[\.\s,‚Äì‚Äî]*[Pp]\.?\s*(\d+)[-‚Äì‚Äî](\d+)', r'\1;\2(\3):\4-\5', text)
    text = re.sub(r'(\d{4})[\.\s,‚Äì‚Äî]*Vol\.?\s*(\d+)[\.\s,‚Äì‚Äî]*[Pp]\.?\s*(\d+)[-‚Äì‚Äî](\d+)', r'\1;\2:\3-\4', text)
    return text.strip()

# --- –Ü–ù–¢–ï–†–§–ï–ô–° ---

st.set_page_config(page_title="–ù–∞—É–∫–æ–≤–∏–π –†–µ–¥–∞–∫—Ç–æ—Ä", page_icon="üìù")
st.title("üìù –ù–∞—É–∫–æ–≤–∏–π –†–µ–¥–∞–∫—Ç–æ—Ä (–°—Ç–∞–Ω–¥–∞—Ä—Ç 14 –ø—Ç, 1.5)")

article_type = st.radio(
    "–û–±–µ—Ä—ñ—Ç—å —Ç–∏–ø –≤–∞—à–æ—ó —Å—Ç–∞—Ç—Ç—ñ:",
    ("–û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è", "–ö–ª—ñ–Ω—ñ—á–Ω–∏–π –≤–∏–ø–∞–¥–æ–∫", "–û–≥–ª—è–¥ –ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏")
)

is_clinical = (article_type == "–ö–ª—ñ–Ω—ñ—á–Ω–∏–π –≤–∏–ø–∞–¥–æ–∫")
is_review = (article_type == "–û–≥–ª—è–¥ –ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏")

uploaded_file = st.file_uploader("–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ñ–∞–π–ª .docx", type="docx")

if uploaded_file is not None:
    if st.button("–û–±—Ä–æ–±–∏—Ç–∏ —Å—Ç–∞—Ç—Ç—é"):
        try:
            doc = Document(uploaded_file)
            report = []
            paras = doc.paragraphs
            text_indices = [i for i, p in enumerate(paras) if p.text.strip()]
            
            ua_kw_idx = next((i for i, p in enumerate(paras) if "–ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞" in p.text), -1)
            en_kw_idx = next((i for i, p in enumerate(paras) if "Key words" in p.text or "Keywords" in p.text), -1)

            if ua_kw_idx == -1 or en_kw_idx == -1:
                st.error("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω—è.")
            else:
                # 1. –®–ê–ü–ö–ê
                paras[text_indices[0]].text = paras[text_indices[0]].text.strip()
                paras[text_indices[1]].text = paras[text_indices[1]].text.strip().upper()
                new_authors_ua = fix_authors_metadata(paras[text_indices[2]].text)
                paras[text_indices[2]].clear()
                add_run(paras[text_indices[2]], new_authors_ua, bold=True, italic=True)

                # 2. –†–û–ó–î–Ü–õ–ò (–ö–∞—Ä—Ç—É–≤–∞–Ω–Ω—è)
                if is_review:
                    sections_map = [(r"^–í—Å—Ç—É–ø", "–í—Å—Ç—É–ø"), (r"^–ú–µ—Ç–∞", "–ú–µ—Ç–∞ —Ä–æ–±–æ—Ç–∏"), (r"^–û—Å–Ω–æ–≤–Ω–∞\s+—á–∞—Å—Ç–∏–Ω–∞", "–û—Å–Ω–æ–≤–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞"), (r"^–í–∏—Å–Ω–æ–≤–æ–∫|^–í–∏—Å–Ω–æ–≤–∫–∏", "–í–∏—Å–Ω–æ–≤–∫–∏"), (r"^–°–ø–∏—Å–æ–∫\s*–ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏|^–õ—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∞|^–°–ø–∏—Å–æ–∫\s*–≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏—Ö\s*–¥–∂–µ—Ä–µ–ª", "–°–ø–∏—Å–æ–∫ –ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏")]
                    all_req = ["–í—Å—Ç—É–ø", "–ú–µ—Ç–∞ —Ä–æ–±–æ—Ç–∏", "–û—Å–Ω–æ–≤–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞", "–í–∏—Å–Ω–æ–≤–∫–∏", "–°–ø–∏—Å–æ–∫ –ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏"]
                elif is_clinical:
                    sections_map = [(r"^–í—Å—Ç—É–ø", "–í—Å—Ç—É–ø"), (r"^–û–ø–∏—Å\s+–∫–ª—ñ–Ω—ñ—á–Ω–æ–≥–æ\s+–≤–∏–ø–∞–¥–∫—É", "–û–ø–∏—Å –∫–ª—ñ–Ω—ñ—á–Ω–æ–≥–æ –≤–∏–ø–∞–¥–∫—É"), (r"^–í–∏—Å–Ω–æ–≤–æ–∫|^–í–∏—Å–Ω–æ–≤–∫–∏", "–í–∏—Å–Ω–æ–≤–æ–∫"), (r"^–°–ø–∏—Å–æ–∫\s*–ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏|^–õ—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∞|^–°–ø–∏—Å–æ–∫\s*–≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏—Ö\s*–¥–∂–µ—Ä–µ–ª", "–°–ø–∏—Å–æ–∫ –ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏")]
                    all_req = ["–í—Å—Ç—É–ø", "–û–ø–∏—Å –∫–ª—ñ–Ω—ñ—á–Ω–æ–≥–æ –≤–∏–ø–∞–¥–∫—É", "–í–∏—Å–Ω–æ–≤–æ–∫", "–°–ø–∏—Å–æ–∫ –ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏"]
                else:
                    sections_map = [(r"^–í—Å—Ç—É–ø", "–í—Å—Ç—É–ø"), (r"^–ú–µ—Ç–∞", "–ú–µ—Ç–∞ —Ä–æ–±–æ—Ç–∏"), (r"^–ú–∞—Ç–µ—Ä—ñ–∞–ª–∏\s*(—ñ|—Ç–∞)\s*–º–µ—Ç–æ–¥–∏", "–ú–∞—Ç–µ—Ä—ñ–∞–ª–∏ —Ç–∞ –º–µ—Ç–æ–¥–∏ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è"), (r"^–†–µ–∑—É–ª—å—Ç–∞—Ç–∏\s*—Ç–∞\s*—ó—Ö\s*–æ–±–≥–æ–≤–æ—Ä–µ–Ω–Ω—è", "–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ —Ç–∞ —ó—Ö –æ–±–≥–æ–≤–æ—Ä–µ–Ω–Ω—è"), (r"^–í–∏—Å–Ω–æ–≤–∫–∏", "–í–∏—Å–Ω–æ–≤–∫–∏"), (r"^–ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–∏\s*–ø–æ–¥–∞–ª—å—à–∏—Ö\s*–¥–æ—Å–ª—ñ–¥–∂–µ–Ω—å", "–ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–∏ –ø–æ–¥–∞–ª—å—à–∏—Ö –¥–æ—Å–ª—ñ–¥–∂–µ–Ω—å"), (r"^–°–ø–∏—Å–æ–∫\s*–ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏|^–õ—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∞|^–°–ø–∏—Å–æ–∫\s*–≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏—Ö\s*–¥–∂–µ—Ä–µ–ª", "–°–ø–∏—Å–æ–∫ –ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏")]
                    all_req = ["–í—Å—Ç—É–ø", "–ú–µ—Ç–∞ —Ä–æ–±–æ—Ç–∏", "–ú–∞—Ç–µ—Ä—ñ–∞–ª–∏ —Ç–∞ –º–µ—Ç–æ–¥–∏ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è", "–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ —Ç–∞ —ó—Ö –æ–±–≥–æ–≤–æ—Ä–µ–Ω–Ω—è", "–í–∏—Å–Ω–æ–≤–∫–∏", "–ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–∏ –ø–æ–¥–∞–ª—å—à–∏—Ö –¥–æ—Å–ª—ñ–¥–∂–µ–Ω—å", "–°–ø–∏—Å–æ–∫ –ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏"]

                in_literature = False
                found_sections = set()

                for i in range(en_kw_idx + 1, len(paras)):
                    p = paras[i]
                    text = p.text.strip()
                    if not text: continue

                    if re.match(r"^References[:.\s]*$", text, re.IGNORECASE):
                        p.clear(); add_run(p, "References", bold=True); in_literature = True; continue

                    matched_std = None
                    for pattern, std_name in sections_map:
                        if re.match(pattern, text, re.IGNORECASE):
                            matched_std = std_name
                            text_after = re.sub(pattern + r"[:.\s-]*", "", text, count=1, flags=re.IGNORECASE).strip()
                            break
                    
                    if matched_std:
                        p.clear(); add_run(p, matched_std, bold=True)
                        found_sections.add(matched_std)
                        in_literature = (matched_std == "–°–ø–∏—Å–æ–∫ –ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–∏")
                        if text_after:
                            new_p = p.insert_paragraph_before(format_vancouver(text_after) if in_literature else text_after)
                    else:
                        if in_literature:
                            for run in p.runs: run.text = format_vancouver(run.text)
                        elif not any(run.text.strip() for run in p.runs): # —è–∫—â–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ –ø—É—Å—Ç–∏–π –∞–±–æ —Ç—ñ–ª—å–∫–∏ –∑ –∫–∞—Ä—Ç–∏–Ω–∫–æ—é
                            pass 

                # --- –§–Ü–ù–ê–õ–¨–ù–ò–ô –¶–ò–ö–õ: –ü–†–ò–ú–£–°–û–í–ï –§–û–†–ú–ê–¢–£–í–ê–ù–ù–Ø –í–°–¨–û–ì–û –¢–ï–ö–°–¢–£ ---
                # –¶–µ –∑–∞—Å—Ç–æ—Å–æ–≤—É—î—Ç—å—Å—è –¥–æ –í–°–Ü–• –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ñ–≤ (—Ç–µ–∫—Å—Ç, –∞–Ω–æ—Ç–∞—Ü—ñ—ó, —Ç–∞–±–ª–∏—Ü—ñ)
                
                def final_format(paragraph):
                    paragraph.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
                    paragraph.paragraph_format.line_spacing = 1.5
                    # –í—Å—Ç–∞–Ω–æ–≤–ª—é—î–º–æ —à—Ä–∏—Ñ—Ç –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ —Ç–µ–∫—Å—Ç—É
                    for run in paragraph.runs:
                        run.font.name = 'Times New Roman'
                        run.font.size = Pt(14)
                        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'Times New Roman')

                # –§–æ—Ä–º–∞—Ç—É—î–º–æ –æ—Å–Ω–æ–≤–Ω—ñ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∏
                for p in doc.paragraphs:
                    final_format(p)
                
                # –§–æ—Ä–º–∞—Ç—É—î–º–æ —Ç–µ–∫—Å—Ç –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ –≤—Å—ñ—Ö —Ç–∞–±–ª–∏—Ü—å
                for table in doc.tables:
                    for row in table.rows:
                        for cell in row.cells:
                            for p in cell.paragraphs:
                                final_format(p)

                for r in all_req:
                    if r not in found_sections: report.append(f"‚ùå –ù–ï –ó–ù–ê–ô–î–ï–ù–û –†–û–ó–î–Ü–õ: {r}")

                bio = BytesIO()
                doc.save(bio)
                
                st.subheader("–ó–≤—ñ—Ç:")
                if not report: st.success("‚úÖ –í—Å–µ —ñ–¥–µ–∞–ª—å–Ω–æ!")
                else:
                    for issue in report: st.error(issue) if "‚ùå" in issue else st.warning(issue)

                st.download_button(label="üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å—Ç–∞—Ç—Ç—é (14 –ø—Ç, 1.5)", data=bio.getvalue(), file_name=f"fixed_{uploaded_file.name}", mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document")

        except Exception as e:
            st.error(f"–ü–æ–º–∏–ª–∫–∞: {e}")